{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72d21b06",
   "metadata": {},
   "source": [
    "# üß™ Pr√°cticas por Dataset de Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eb189a",
   "metadata": {},
   "source": [
    "## üõçÔ∏è Retail Sales Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02061b7c",
   "metadata": {},
   "source": [
    "üîó Dataset disponible en: [https://www.kaggle.com/datasets/mohammadtalib786/retail-sales-dataset?utm_source=chatgpt.com](https://www.kaggle.com/datasets/mohammadtalib786/retail-sales-dataset?utm_source=chatgpt.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37531725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar pandas\n",
    "import pandas as pd \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbccb633",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargar el dataset\n",
    "df_retail= pd.read_csv('./datasets/retail_sales_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d7c484",
   "metadata": {},
   "source": [
    "**Pregunta:** ¬øCu√°ntas filas y columnas tiene el dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45331714",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filas, num_columnas = df_retail.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6464ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataset tiene 1000 filas y 9 columnas\n"
     ]
    }
   ],
   "source": [
    "print(f\"El dataset tiene {num_filas} filas y {num_columnas} columnas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07757d0",
   "metadata": {},
   "source": [
    "**Pregunta:** ¬øCu√°les son los tipos de datos de cada columna?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bffb05e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction ID       int64\n",
      "Date                object\n",
      "Customer ID         object\n",
      "Gender              object\n",
      "Age                  int64\n",
      "Product Category    object\n",
      "Quantity             int64\n",
      "Price per Unit       int64\n",
      "Total Amount         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# cuales son los tipos de datos de las columnas\n",
    "print(df_retail.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6630efce",
   "metadata": {},
   "source": [
    "**Pregunta:** ¬øQu√© productos tienen mayores ventas en cantidad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b131e104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Category\n",
      "Clothing       894\n",
      "Electronics    849\n",
      "Beauty         771\n",
      "Name: Quantity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# productos tienen mayores ventas en cantidad\n",
    "#\n",
    "productos_ventas = df_retail.groupby('Product Category')['Quantity'].sum().sort_values(ascending=False).head(10)\n",
    "print(productos_ventas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74d87ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Transaction ID   Store\n",
      "0               1   Oeste\n",
      "1               2   Oeste\n",
      "2               3  Centro\n",
      "3               4    Este\n",
      "4               5     Sur\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Crear lista de nombres de tiendas ficticias\n",
    "tiendas = ['Norte', 'Sur', 'Centro', 'Este', 'Oeste']\n",
    "\n",
    "# Asignar aleatoriamente una tienda a cada transacci√≥n\n",
    "df_retail['Store'] = np.random.choice(tiendas, size=len(df_retail))\n",
    "\n",
    "# Verificar\n",
    "print(df_retail[['Transaction ID', 'Store']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "214a7b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario de mapeo de categor√≠a a tienda\n",
    "mapeo_tiendas = {\n",
    "    'Clothing': 'Tienda Moda',\n",
    "    'Electronics': 'Tienda Tecnolog√≠a',\n",
    "    'Beauty': 'Tienda Belleza'\n",
    "}\n",
    "\n",
    "# Crear columna basada en categor√≠a\n",
    "df_retail['Store'] = df_retail['Product Category'].map(mapeo_tiendas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0bfc4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suponiendo que 'Customer ID' contiene informaci√≥n geogr√°fica\n",
    "df_retail['Store'] = df_retail['Customer ID'].apply(lambda x: 'Norte' if x.startswith('N') else 'Sur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "933c2e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ventas por tienda (cantidad):\n",
      "Store\n",
      "Tienda Moda          894\n",
      "Tienda Tecnolog√≠a    849\n",
      "Tienda Belleza       771\n",
      "Name: Quantity, dtype: int64\n",
      "\n",
      "Ingresos por tienda:\n",
      "Store\n",
      "Tienda Tecnolog√≠a    156905\n",
      "Tienda Moda          155580\n",
      "Tienda Belleza       143515\n",
      "Name: Total Amount, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ventas por tienda (cantidad)\n",
    "ventas_por_tienda = df_retail.groupby('Store')['Quantity'].sum().sort_values(ascending=False)\n",
    "print(\"\\nVentas por tienda (cantidad):\")\n",
    "print(ventas_por_tienda)\n",
    "\n",
    "# Ingresos por tienda (monto total)\n",
    "ingresos_por_tienda = df_retail.groupby('Store')['Total Amount'].sum().sort_values(ascending=False)\n",
    "print(\"\\nIngresos por tienda:\")\n",
    "print(ingresos_por_tienda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43679905",
   "metadata": {},
   "source": [
    "**Pregunta:** ¬øQu√© tiendas venden m√°s productos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84090e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribuci√≥n porcentual por tienda:\n",
      "Store\n",
      "Sur    100.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Qu√© tiendas venden m√°s productos\n",
    "\n",
    "tiendas_ventas = df_retail.groupby('Store')['Quantity'].sum().sort_values(ascending=False)\n",
    "porcentaje_ventas = (df_retail['Store'].value_counts(normalize=True) * 100).round(1)\n",
    "print(\"\\nDistribuci√≥n porcentual por tienda:\")\n",
    "print(porcentaje_ventas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c5fba1",
   "metadata": {},
   "source": [
    "**Pregunta:** ¬øExisten datos faltantes o duplicados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e6f51e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction ID      0\n",
      "Date                0\n",
      "Customer ID         0\n",
      "Gender              0\n",
      "Age                 0\n",
      "Product Category    0\n",
      "Quantity            0\n",
      "Price per Unit      0\n",
      "Total Amount        0\n",
      "Store               0\n",
      "dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# existen dotos faltantes o duplicados \n",
    "print(df_retail.isnull().sum())\n",
    "print(df_retail.duplicated().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5ab1bf",
   "metadata": {},
   "source": [
    "**Pregunta:** ¬øCu√°l es el ingreso total por tienda?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165c4bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El ingreso total de la tienda es: 456000\n"
     ]
    }
   ],
   "source": [
    "#cual es el ingreso total de la tienda }\n",
    "ingreso_total = df_retail['Total Amount'].sum()\n",
    "print(f'El ingreso total de la tienda es: {ingreso_total}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59869563",
   "metadata": {},
   "source": [
    "**Pregunta:** Agrupa las ventas por tipo de producto y encuentra la media de precios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877429e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Category\n",
      "Beauty         184.055375\n",
      "Clothing       174.287749\n",
      "Electronics    181.900585\n",
      "Name: Price per Unit, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Agrupa las ventas por tipo de producto y encuentra la media de precios\n",
    "mean_prices = df_retail.groupby('Product Category')['Price per Unit'].mean()\n",
    "print(mean_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de016c86",
   "metadata": {},
   "source": [
    "**Pregunta:** Crea una nueva columna llamada `ingreso_total` que sea precio * cantidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5154805b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Price per Unit  Quantity  ingreso_total\n",
      "0              50         3            150\n",
      "1             500         2           1000\n",
      "2              30         1             30\n",
      "3             500         1            500\n",
      "4              50         2            100\n"
     ]
    }
   ],
   "source": [
    "# Crea una nueva columna llamada `ingreso_total` que sea precio * cantidad.\n",
    "df_retail['ingreso_total'] = df_retail['Price per Unit'] * df_retail['Quantity']\n",
    "print(df_retail[['Price per Unit', 'Quantity', 'ingreso_total']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f370183a",
   "metadata": {},
   "source": [
    "**Pregunta:** Usa una tabla din√°mica para comparar ingresos por tienda y por producto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e76f6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Category  Beauty  Clothing  Electronics\n",
      "Price per Unit                                 \n",
      "25                  3925      4600         4525\n",
      "30                  3990      5130         4230\n",
      "50                  8500      9450         8750\n",
      "300                42600     57900        54900\n",
      "500                84500     78500        84500\n"
     ]
    }
   ],
   "source": [
    "# Usa una tabla din√°mica para comparar ingresos por tienda y por producto.\n",
    "pivot_table = df_retail.pivot_table(values='ingreso_total', index='Price per Unit', columns='Product Category', aggfunc='sum', fill_value=0)\n",
    "print(pivot_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edf618c",
   "metadata": {},
   "source": [
    "## üìà Dummy Advertising and Sales Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a5c26d",
   "metadata": {},
   "source": [
    "üîó Dataset disponible en: [https://www.kaggle.com/datasets/harrimansaragih/dummy-advertising-and-sales-data?utm_source=chatgpt.com](https://www.kaggle.com/datasets/harrimansaragih/dummy-advertising-and-sales-data?utm_source=chatgpt.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11108f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af1f7ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_data =pd.read_csv('./datasets/Dummy Data HSS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "774be4d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version https://git-lfs.github.com/spec/v1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oid sha256:79948d29df471e3112679d7db719f621076...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>size 201852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          version https://git-lfs.github.com/spec/v1\n",
       "0  oid sha256:79948d29df471e3112679d7db719f621076...\n",
       "1                                        size 201852"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad70e47d",
   "metadata": {},
   "source": [
    "**Pregunta:** ¬øCu√°l es el gasto promedio en publicidad por canal (TV, Radio, Peri√≥dico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1bb9a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TV              54.066857\n",
      "Radio           18.160356\n",
      "Social Media     3.323956\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Cu√°l es el gasto promedio en publicidad por canal (TV, Radio, Social Media)\n",
    "avg_ad_spend = dummy_data[['TV', 'Radio', 'Social Media']].mean()\n",
    "print(avg_ad_spend)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fea9b5",
   "metadata": {},
   "source": [
    "**Pregunta:** ¬øExiste correlaci√≥n entre el presupuesto publicitario y las ventas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7b12a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales           1.000000\n",
      "TV              0.999497\n",
      "Radio           0.869105\n",
      "Social Media    0.528906\n",
      "Name: Sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Existe correlaci√≥n entre el presupuesto publicitario y las ventas}\n",
    "correlation = dummy_data[['TV', 'Radio', 'Social Media', 'Sales']].corr()\n",
    "print(correlation['Sales'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bee9c70",
   "metadata": {},
   "source": [
    "**Pregunta:** ¬øQu√© campa√±as tienen ventas superiores a la media?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc35b9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        TV      Radio  Social Media Influencer       Sales\n",
      "3     83.0  30.020028      6.922304       Mega  298.246340\n",
      "6     55.0  24.893811      4.273602      Micro  198.679825\n",
      "8     76.0  24.648898      7.130116      Macro  270.189400\n",
      "10    62.0  24.345189      5.151483       Nano  224.961019\n",
      "12    64.0  20.240424      3.921148      Micro  229.632381\n",
      "...    ...        ...           ...        ...         ...\n",
      "4561  60.0  21.841864      5.092528      Macro  210.680016\n",
      "4563  93.0  25.285149      2.805840      Macro  327.466288\n",
      "4564  99.0  36.024174      4.288755      Macro  355.807121\n",
      "4568  71.0  20.610685      6.545573       Nano  249.101915\n",
      "4570  71.0  17.534640      1.940873      Macro  253.610411\n",
      "\n",
      "[2239 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Qu√© campa√±as tienen ventas superiores a la media \n",
    "mean_sales = dummy_data['Sales'].mean()\n",
    "high_sales_campaigns = dummy_data[dummy_data['Sales'] > mean_sales]     \n",
    "print(high_sales_campaigns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0057c81",
   "metadata": {},
   "source": [
    "**Pregunta:** Filtra las campa√±as con publicidad en TV > 200 y Radio > 20."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab19f30",
   "metadata": {},
   "source": [
    "se cambia de 200 a 20 por que no sale lo cambie por 20 a 5 para que podamos ver que saldria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234492a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        TV      Radio  Social Media Influencer       Sales\n",
      "0     16.0   6.566231      2.907983       Mega   54.732757\n",
      "1     13.0   9.237765      2.409567       Mega   46.677897\n",
      "2     41.0  15.886446      2.913410       Mega  150.177829\n",
      "3     83.0  30.020028      6.922304       Mega  298.246340\n",
      "4     15.0   8.437408      1.405998      Micro   56.594181\n",
      "...    ...        ...           ...        ...         ...\n",
      "4567  26.0   4.472360      0.717090      Micro   94.685866\n",
      "4568  71.0  20.610685      6.545573       Nano  249.101915\n",
      "4569  44.0  19.800072      5.096192      Micro  163.631457\n",
      "4570  71.0  17.534640      1.940873      Macro  253.610411\n",
      "4571  42.0  15.966688      5.046548      Micro  148.202414\n",
      "\n",
      "[4562 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "high_tv_radio_campaigns = dummy_data[(dummy_data['TV'] > 20 & (dummy_data['Radio'] > 5)) | (dummy_data['TV'] > 20 & (dummy_data['Radio'] > 5))]\n",
    "print(high_tv_radio_campaigns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fec181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [TV, Radio, Social Media, Influencer, Sales]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#  Filtra las campa√±as con publicidad en TV > 200 y Radio > 20.\n",
    "high_tv_radio_campaigns = dummy_data[(dummy_data['TV'] > 200) & (dummy_data['Radio'] > 20)]\n",
    "print(high_tv_radio_campaigns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4bd8b6",
   "metadata": {},
   "source": [
    "**Pregunta:** Agrupa por canal publicitario y calcula la media de ventas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0d6662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TV     Radio      Social Media\n",
      "10.0   0.573244   1.072542         33.719607\n",
      "       0.688749   0.982756         33.459886\n",
      "       0.758569   0.527881         35.547998\n",
      "       0.858810   3.621606         36.882298\n",
      "       1.179967   0.939789         34.205170\n",
      "                                     ...    \n",
      "100.0  42.225232  8.977117        364.079751\n",
      "       42.832653  3.965113        354.869546\n",
      "       43.760694  6.420971        350.087078\n",
      "       44.560410  8.470340        357.092487\n",
      "       45.082921  4.511628        352.657695\n",
      "Name: Sales, Length: 4552, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Agrupa por canal publicitario y calcula la media de ventas\n",
    "mean_sales_by_channel = dummy_data.groupby(['TV', 'Radio', 'Social Media'])['Sales'].mean()\n",
    "print(mean_sales_by_channel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33653619",
   "metadata": {},
   "source": [
    "**Pregunta:** Crea una columna de ROI estimado usando una f√≥rmula simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054ad8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Sales    TV      Radio  Social Media  Estimated ROI\n",
      "0   54.732757  16.0   6.566231      2.907983       1.148555\n",
      "1   46.677897  13.0   9.237765      2.409567       0.893832\n",
      "2  150.177829  41.0  15.886446      2.913410       1.511341\n",
      "3  298.246340  83.0  30.020028      6.922304       1.486581\n",
      "4   56.594181  15.0   8.437408      1.405998       1.278036\n"
     ]
    }
   ],
   "source": [
    "# Crea una columna de ROI estimado usando una f√≥rmula simple\n",
    "dummy_data['Estimated ROI'] = (dummy_data['Sales'] - (dummy_data['TV'] + dummy_data['Radio'] + dummy_data['Social Media'])) / (dummy_data['TV'] + dummy_data['Radio'] + dummy_data['Social Media'])\n",
    "print(dummy_data[['Sales', 'TV', 'Radio', 'Social Media', 'Estimated ROI']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbbc592",
   "metadata": {},
   "source": [
    "**Pregunta:** Realiza una pivot_table para ver ventas promedio por cada tipo de canal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd172f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Radio  0.000684   0.014486   0.021883   0.026295   0.038151   0.043082   \\\n",
      "TV                                                                        \n",
      "10.0         0.0   0.000000   0.000000        0.0   0.000000        0.0   \n",
      "11.0         0.0   0.000000   0.000000        0.0  34.059559        0.0   \n",
      "12.0         0.0   0.000000   0.000000        0.0   0.000000        0.0   \n",
      "13.0         0.0  45.032326   0.000000        0.0   0.000000        0.0   \n",
      "14.0         0.0   0.000000  53.702021        0.0   0.000000        0.0   \n",
      "...          ...        ...        ...        ...        ...        ...   \n",
      "96.0         0.0   0.000000   0.000000        0.0   0.000000        0.0   \n",
      "97.0         0.0   0.000000   0.000000        0.0   0.000000        0.0   \n",
      "98.0         0.0   0.000000   0.000000        0.0   0.000000        0.0   \n",
      "99.0         0.0   0.000000   0.000000        0.0   0.000000        0.0   \n",
      "100.0        0.0   0.000000   0.000000        0.0   0.000000        0.0   \n",
      "\n",
      "Radio  0.066123   0.084175   0.095047   0.103555   ...  42.271579   42.331654  \\\n",
      "TV                                                 ...                          \n",
      "10.0         0.0        0.0   0.000000        0.0  ...        0.0    0.000000   \n",
      "11.0         0.0        0.0   0.000000        0.0  ...        0.0    0.000000   \n",
      "12.0         0.0        0.0   0.000000        0.0  ...        0.0    0.000000   \n",
      "13.0         0.0        0.0  44.179451        0.0  ...        0.0    0.000000   \n",
      "14.0         0.0        0.0   0.000000        0.0  ...        0.0    0.000000   \n",
      "...          ...        ...        ...        ...  ...        ...         ...   \n",
      "96.0         0.0        0.0   0.000000        0.0  ...        0.0    0.000000   \n",
      "97.0         0.0        0.0   0.000000        0.0  ...        0.0  348.392736   \n",
      "98.0         0.0        0.0   0.000000        0.0  ...        0.0    0.000000   \n",
      "99.0         0.0        0.0   0.000000        0.0  ...        0.0    0.000000   \n",
      "100.0        0.0        0.0   0.000000        0.0  ...        0.0    0.000000   \n",
      "\n",
      "Radio   42.832653  43.129332   43.760694   44.560410   44.861299   45.082921  \\\n",
      "TV                                                                             \n",
      "10.0     0.000000        0.0    0.000000    0.000000    0.000000    0.000000   \n",
      "11.0     0.000000        0.0    0.000000    0.000000    0.000000    0.000000   \n",
      "12.0     0.000000        0.0    0.000000    0.000000    0.000000    0.000000   \n",
      "13.0     0.000000        0.0    0.000000    0.000000    0.000000    0.000000   \n",
      "14.0     0.000000        0.0    0.000000    0.000000    0.000000    0.000000   \n",
      "...           ...        ...         ...         ...         ...         ...   \n",
      "96.0     0.000000        0.0    0.000000    0.000000    0.000000    0.000000   \n",
      "97.0     0.000000        0.0    0.000000    0.000000    0.000000    0.000000   \n",
      "98.0     0.000000        0.0    0.000000    0.000000    0.000000    0.000000   \n",
      "99.0     0.000000        0.0    0.000000    0.000000  355.148081    0.000000   \n",
      "100.0  354.869546        0.0  350.087078  357.092487    0.000000  352.657695   \n",
      "\n",
      "Radio  47.116293   48.871161  \n",
      "TV                            \n",
      "10.0         0.0    0.000000  \n",
      "11.0         0.0    0.000000  \n",
      "12.0         0.0    0.000000  \n",
      "13.0         0.0    0.000000  \n",
      "14.0         0.0    0.000000  \n",
      "...          ...         ...  \n",
      "96.0         0.0    0.000000  \n",
      "97.0         0.0    0.000000  \n",
      "98.0         0.0    0.000000  \n",
      "99.0         0.0  349.156031  \n",
      "100.0        0.0    0.000000  \n",
      "\n",
      "[91 rows x 4552 columns]\n"
     ]
    }
   ],
   "source": [
    "# Realiza una pivot_table para ver ventas promedio por cada tipo de canal\n",
    "pivot_table = dummy_data.pivot_table(values='Sales', index='TV', columns='Radio', aggfunc='mean', fill_value=0)\n",
    "print(pivot_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29509792",
   "metadata": {},
   "source": [
    "## üé¨ The Movies Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0b2ee1",
   "metadata": {},
   "source": [
    "üîó Dataset disponible en: [https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset?utm_source=chatgpt.com](https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset?utm_source=chatgpt.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2eaf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fda8825",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_daily = pd.read_csv('./datasets/movie_daily.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f78c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "Movie_franchise = pd.read_csv('./datasets/MovieFranchises.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaf5711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Distr</th>\n",
       "      <th>Gross</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Despicable Me 2</td>\n",
       "      <td>Universal</td>\n",
       "      <td>6845130</td>\n",
       "      <td>2013/07/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Grown Ups 2</td>\n",
       "      <td>Sony Pictures</td>\n",
       "      <td>5273521</td>\n",
       "      <td>2013/07/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Pacific Rim</td>\n",
       "      <td>Warner Bros.</td>\n",
       "      <td>4416340</td>\n",
       "      <td>2013/07/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The Heat</td>\n",
       "      <td>20th Century‚Ä¶</td>\n",
       "      <td>2175635</td>\n",
       "      <td>2013/07/16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Monsters University</td>\n",
       "      <td>Walt Disney</td>\n",
       "      <td>1931131</td>\n",
       "      <td>2013/07/16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                Movie          Distr    Gross        date\n",
       "0      0      Despicable Me 2      Universal  6845130  2013/07/16\n",
       "1      1          Grown Ups 2  Sony Pictures  5273521  2013/07/16\n",
       "2      2          Pacific Rim   Warner Bros.  4416340  2013/07/16\n",
       "3      3             The Heat  20th Century‚Ä¶  2175635  2013/07/16\n",
       "4      4  Monsters University    Walt Disney  1931131  2013/07/16"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737e63b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas disponibles: ['index', 'Movie', 'Distr', 'Gross', 'date']\n"
     ]
    }
   ],
   "source": [
    "# Verifica las columnas disponibles\n",
    "print(\"Columnas disponibles:\", movie_daily.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fded589f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index     int64\n",
      "Movie    object\n",
      "Distr    object\n",
      "Gross     int64\n",
      "date     object\n",
      "dtype: object\n",
      "Index(['index', 'Movie', 'Distr', 'Gross', 'date'], dtype='object')\n",
      "   index                Movie          Distr    Gross        date\n",
      "0      0      Despicable Me 2      Universal  6845130  2013/07/16\n",
      "1      1          Grown Ups 2  Sony Pictures  5273521  2013/07/16\n",
      "2      2          Pacific Rim   Warner Bros.  4416340  2013/07/16\n",
      "3      3             The Heat  20th Century‚Ä¶  2175635  2013/07/16\n",
      "4      4  Monsters University    Walt Disney  1931131  2013/07/16\n"
     ]
    }
   ],
   "source": [
    "print(movie_daily.dtypes)\n",
    "\n",
    "print(movie_daily.columns)\n",
    "\n",
    "\n",
    "print(movie_daily.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51caea6",
   "metadata": {},
   "source": [
    "**Pregunta:** ¬øCu√°les son las pel√≠culas con mayor presupuesto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd22d5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pel√≠culas con mayores ingresos diarios:\n",
      "                      Movie     Gross\n",
      "          Avengers: Endgame 157461641\n",
      " Star Wars Ep. VII: The Fo‚Ä¶ 119119282\n",
      "          Avengers: Endgame 109264122\n",
      "     Avengers: Infinity War 106334939\n",
      " Star Wars Ep. VIII: The L‚Ä¶ 104684491\n",
      "          Avengers: Endgame  90389244\n",
      " Star Wars: The Rise of Sk‚Ä¶  89615288\n",
      "The Avengers: Age of Ultron  84424532\n",
      "     Avengers: Infinity War  82131612\n",
      "             Jurassic World  81953950\n"
     ]
    }
   ],
   "source": [
    "# Top 10 pel√≠culas con mayores ingresos diarios (Gross)\n",
    "top_gross = movie_daily[['Movie', 'Gross']].sort_values('Gross', ascending=False).head(10)\n",
    "print(\"Pel√≠culas con mayores ingresos diarios:\")\n",
    "print(top_gross.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e333b7d",
   "metadata": {},
   "source": [
    "**Pregunta:** ¬øQu√© pel√≠culas obtuvieron mayor ganancia (ingresos - presupuesto)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7100e36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pel√≠culas con mayor ganancia:\n",
      "                      Movie     Gross    Profit\n",
      "          Avengers: Endgame 157461641 157461641\n",
      " Star Wars Ep. VII: The Fo‚Ä¶ 119119282 119119282\n",
      "          Avengers: Endgame 109264122 109264122\n",
      "     Avengers: Infinity War 106334939 106334939\n",
      " Star Wars Ep. VIII: The L‚Ä¶ 104684491 104684491\n",
      "          Avengers: Endgame  90389244  90389244\n",
      " Star Wars: The Rise of Sk‚Ä¶  89615288  89615288\n",
      "The Avengers: Age of Ultron  84424532  84424532\n",
      "     Avengers: Infinity War  82131612  82131612\n",
      "             Jurassic World  81953950  81953950\n"
     ]
    }
   ],
   "source": [
    "# Qu√© pel√≠culas obtuvieron mayor ganancia (ingresos - presupuesto)\n",
    "top_profit = movie_daily[['Movie', 'Gross']].assign(Profit=lambda x: x['Gross']).sort_values('Profit', ascending=False).head(10)\n",
    "print(\"\\nPel√≠culas con mayor ganancia:\")\n",
    "print(top_profit.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b00dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['index', 'Movie', 'Distr', 'Gross', 'date']\n",
      "\n",
      "Pel√≠culas por distribuidora:\n",
      "Distr\n",
      "Warner Bros.     12433\n",
      "20th Century‚Ä¶     9779\n",
      "Sony Pictures     8985\n",
      "Universal         8524\n",
      "Lionsgate         7741\n",
      "                 ...  \n",
      "Drafthouse F‚Ä¶        1\n",
      "MUBI                 1\n",
      "Parade Deck ‚Ä¶        1\n",
      "Carpe Stella         1\n",
      "Area 23a             1\n",
      "Name: count, Length: 213, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verifica si hay alguna columna que pueda servir como categor√≠a\n",
    "print(movie_daily.columns.tolist())  \n",
    "\n",
    "# Ejemplo usando Distribuidora (Distr) como alternativa\n",
    "if 'Distr' in movie_daily.columns:\n",
    "    distr_counts = movie_daily['Distr'].value_counts()\n",
    "    print(\"\\nPel√≠culas por distribuidora:\")\n",
    "    print(distr_counts)\n",
    "else:\n",
    "    print(\"No hay columnas de categor√≠a disponibles en este dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165ce1f0",
   "metadata": {},
   "source": [
    "**Pregunta:** ¬øCu√°ntas pel√≠culas hay por g√©nero?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faad1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cantidad de pel√≠culas por g√©nero:\n",
      "Movie\n",
      "Island of Lemurs: Madagascar    354\n",
      "The Hunger Games: Mocking‚Ä¶      219\n",
      "Free Solo                       216\n",
      "Gravity                         215\n",
      "The Lego Movie                  210\n",
      "                               ... \n",
      "Amy                               1\n",
      "Jimmy's Hall                      1\n",
      "Maggie                            1\n",
      "Gemma Bovery                      1\n",
      "Testament of Youth                1\n",
      "Name: count, Length: 2134, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# cuantas peliculas hay por g√©nero\n",
    "genre_counts = movie_daily['Movie'].value_counts()\n",
    "print(\"\\nCantidad de pel√≠culas por g√©nero:\")\n",
    "print(genre_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac0319c",
   "metadata": {},
   "source": [
    "**Pregunta:** ¬øExisten pel√≠culas con presupuesto o ingresos nulos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f114905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pel√≠culas con presupuesto o ingreso nulo:\n",
      "              Movie Distr   Gross\n",
      "40              NaN   NaN      48\n",
      "82              NaN   NaN     152\n",
      "125             NaN   NaN     133\n",
      "165             NaN   NaN     123\n",
      "205             NaN   NaN      71\n",
      "...             ...   ...     ...\n",
      "83170  Perfect Blue   NaN     674\n",
      "83219  Perfect Blue   NaN    2155\n",
      "83281  Perfect Blue   NaN     920\n",
      "83347  Perfect Blue   NaN     772\n",
      "99028  Dear Comrade   NaN  457000\n",
      "\n",
      "[172 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# existen peliculas con presupesto o ingreso nulo \n",
    "null_movies = movie_daily[movie_daily['Distr'].isnull() | movie_daily['Gross'].isnull()]\n",
    "if not null_movies.empty:\n",
    "    print(\"\\nPel√≠culas con presupuesto o ingreso nulo:\")\n",
    "    print(null_movies[['Movie', 'Distr', 'Gross']])\n",
    "else:\n",
    "    print(\"No hay pel√≠culas con presupuesto o ingreso nulo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fcf2bc",
   "metadata": {},
   "source": [
    "**Pregunta:** Crea una nueva columna de rentabilidad (ganancia/presupuesto)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daca86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Movie    Gross  Budget  Rentabilidad\n",
      "0      Despicable Me 2  6845130     0.0           inf\n",
      "1          Grown Ups 2  5273521     0.0           inf\n",
      "2          Pacific Rim  4416340     0.0           inf\n",
      "3             The Heat  2175635     0.0           inf\n",
      "4  Monsters University  1931131     0.0           inf\n"
     ]
    }
   ],
   "source": [
    "# Unir presupuesto desde Movie_franchise\n",
    "movie_daily = movie_daily.merge(\n",
    "    Movie_franchise[['Title', 'Budget']],\n",
    "    left_on='Movie',\n",
    "    right_on='Title',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Limpiar presupuesto a num√©rico\n",
    "movie_daily['Budget'] = (\n",
    "    movie_daily['Budget']\n",
    "    .astype(str)\n",
    "    .str.replace(r'[^0-9.]', '', regex=True)\n",
    "    .replace('', '0')\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "# Calcular rentabilidad\n",
    "movie_daily['Rentabilidad'] = (\n",
    "    movie_daily['Gross'] - movie_daily['Budget']\n",
    ") / movie_daily['Budget']\n",
    "\n",
    "print(movie_daily[['Movie', 'Gross', 'Budget', 'Rentabilidad']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5676dda",
   "metadata": {},
   "source": [
    "**Pregunta:** Agrupa por a√±o de lanzamiento y calcula ingresos promedio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9bce93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year  Ingreso Promedio\n",
      "0  2013     644874.290173\n",
      "1  2014     691907.382737\n",
      "2  2015     772615.352941\n",
      "3  2016     689819.505449\n",
      "4  2017     646944.925885\n"
     ]
    }
   ],
   "source": [
    "# Crear columna Year desde date\n",
    "movie_daily['date'] = pd.to_datetime(movie_daily['date'], errors='coerce')\n",
    "movie_daily['Year'] = movie_daily['date'].dt.year\n",
    "\n",
    "# Agrupar por a√±o y calcular promedio de Gross\n",
    "ingreso_promedio_por_ano = (\n",
    "    movie_daily.groupby('Year')['Gross']\n",
    "    .mean()\n",
    "    .reset_index(name='Ingreso Promedio')\n",
    ")\n",
    "\n",
    "print(ingreso_promedio_por_ano.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6584ece9",
   "metadata": {},
   "source": [
    "**Pregunta:** Realiza una tabla din√°mica que compare ingresos por g√©nero y a√±o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0477801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year                2013        2014        2015        2016        2017  \\\n",
      "Distr                                                                      \n",
      "101 Studios            0           0           0           0           0   \n",
      "1091 Media             0           0           0           0           0   \n",
      "20th Century‚Ä¶  452313791  1818828936  1316958058  1499089514  1352981840   \n",
      "3DLive                 0           0           0           0           0   \n",
      "A24              5265338      409600    15996304    52781473   102387948   \n",
      "\n",
      "Year                 2018       2019       2020  \n",
      "Distr                                            \n",
      "101 Studios             0    5978643   18606492  \n",
      "1091 Media              0     721341      26343  \n",
      "20th Century‚Ä¶  1114546358  483730493  158515896  \n",
      "3DLive                  0          0      31252  \n",
      "A24              92710338   94964952   26047848  \n"
     ]
    }
   ],
   "source": [
    "tabla_dinamica = movie_daily.pivot_table(\n",
    "    values='Gross',\n",
    "    index='Distr',     # si tienes 'Genero', c√°mbialo aqu√≠\n",
    "    columns='Year',\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "print(tabla_dinamica.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4f305a",
   "metadata": {},
   "source": [
    "## üå¶Ô∏è Climate Insights Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a90026",
   "metadata": {},
   "source": [
    "üîó Dataset disponible en: [https://www.kaggle.com/datasets/goyaladi/climate-insights-dataset?utm_source=chatgpt.com](https://www.kaggle.com/datasets/goyaladi/climate-insights-dataset?utm_source=chatgpt.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b27bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5206200",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_change = pd.read_csv('./datasets/climate_change_data.csv')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6532266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>Country</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>CO2 Emissions</th>\n",
       "      <th>Sea Level Rise</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind Speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-01 00:00:00.000000000</td>\n",
       "      <td>New Williamtown</td>\n",
       "      <td>Latvia</td>\n",
       "      <td>10.688986</td>\n",
       "      <td>403.118903</td>\n",
       "      <td>0.717506</td>\n",
       "      <td>13.835237</td>\n",
       "      <td>23.631256</td>\n",
       "      <td>18.492026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-01 20:09:43.258325832</td>\n",
       "      <td>North Rachel</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>13.814430</td>\n",
       "      <td>396.663499</td>\n",
       "      <td>1.205715</td>\n",
       "      <td>40.974084</td>\n",
       "      <td>43.982946</td>\n",
       "      <td>34.249300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-02 16:19:26.516651665</td>\n",
       "      <td>West Williamland</td>\n",
       "      <td>French Guiana</td>\n",
       "      <td>27.323718</td>\n",
       "      <td>451.553155</td>\n",
       "      <td>-0.160783</td>\n",
       "      <td>42.697931</td>\n",
       "      <td>96.652600</td>\n",
       "      <td>34.124261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-03 12:29:09.774977497</td>\n",
       "      <td>South David</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>12.309581</td>\n",
       "      <td>422.404983</td>\n",
       "      <td>-0.475931</td>\n",
       "      <td>5.193341</td>\n",
       "      <td>47.467938</td>\n",
       "      <td>8.554563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-04 08:38:53.033303330</td>\n",
       "      <td>New Scottburgh</td>\n",
       "      <td>Moldova</td>\n",
       "      <td>13.210885</td>\n",
       "      <td>410.472999</td>\n",
       "      <td>1.135757</td>\n",
       "      <td>78.695280</td>\n",
       "      <td>61.789672</td>\n",
       "      <td>8.001164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Date          Location        Country  \\\n",
       "0  2000-01-01 00:00:00.000000000   New Williamtown         Latvia   \n",
       "1  2000-01-01 20:09:43.258325832      North Rachel   South Africa   \n",
       "2  2000-01-02 16:19:26.516651665  West Williamland  French Guiana   \n",
       "3  2000-01-03 12:29:09.774977497       South David        Vietnam   \n",
       "4  2000-01-04 08:38:53.033303330    New Scottburgh        Moldova   \n",
       "\n",
       "   Temperature  CO2 Emissions  Sea Level Rise  Precipitation   Humidity  \\\n",
       "0    10.688986     403.118903        0.717506      13.835237  23.631256   \n",
       "1    13.814430     396.663499        1.205715      40.974084  43.982946   \n",
       "2    27.323718     451.553155       -0.160783      42.697931  96.652600   \n",
       "3    12.309581     422.404983       -0.475931       5.193341  47.467938   \n",
       "4    13.210885     410.472999        1.135757      78.695280  61.789672   \n",
       "\n",
       "   Wind Speed  \n",
       "0   18.492026  \n",
       "1   34.249300  \n",
       "2   34.124261  \n",
       "3    8.554563  \n",
       "4    8.001164  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_change.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812ef6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas disponibles: ['Date', 'Location', 'Country', 'Temperature', 'CO2 Emissions', 'Sea Level Rise', 'Precipitation', 'Humidity', 'Wind Speed']\n"
     ]
    }
   ],
   "source": [
    "print(\"Columnas disponibles:\",climate_change.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecca5780",
   "metadata": {},
   "source": [
    "**Pregunta:** ¬øCu√°ntos registros hay por a√±o?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9231b5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Registros por a√±o:\n",
      "Year\n",
      "2000    436\n",
      "2001    435\n",
      "2002    434\n",
      "2003    435\n",
      "2004    435\n",
      "2005    435\n",
      "2006    434\n",
      "2007    435\n",
      "2008    435\n",
      "2009    435\n",
      "2010    434\n",
      "2011    435\n",
      "2012    436\n",
      "2013    434\n",
      "2014    434\n",
      "2015    435\n",
      "2016    436\n",
      "2017    434\n",
      "2018    435\n",
      "2019    434\n",
      "2020    436\n",
      "2021    434\n",
      "2022    434\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convertir la columna Date a datetime y extraer el a√±o\n",
    "climate_change['Date'] = pd.to_datetime(climate_change['Date'])\n",
    "climate_change['Year'] = climate_change['Date'].dt.year\n",
    "\n",
    "# Contar registros por a√±o\n",
    "registros_por_a√±o = climate_change['Year'].value_counts().sort_index()\n",
    "print(\"\\nRegistros por a√±o:\")\n",
    "print(registros_por_a√±o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ab7dce",
   "metadata": {},
   "source": [
    "**Pregunta:** ¬øCu√°l es la temperatura media mensual m√°s alta y m√°s baja?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daf20b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mes m√°s c√°lido: (np.int32(2014), np.int32(2)) con 17.75¬∞C\n",
      "Mes m√°s fr√≠o: (np.int32(2022), np.int32(3)) con 12.73¬∞C\n"
     ]
    }
   ],
   "source": [
    "# Tu c√≥digo aqu√≠\n",
    "# Extraer mes y a√±o\n",
    "climate_change['Month'] = climate_change['Date'].dt.month\n",
    "\n",
    "# Calcular medias mensuales\n",
    "temp_mensual = climate_change.groupby(['Year', 'Month'])['Temperature'].mean()\n",
    "\n",
    "# Encontrar valores extremos\n",
    "max_temp = temp_mensual.idxmax()\n",
    "min_temp = temp_mensual.idxmin()\n",
    "\n",
    "print(f\"\\nMes m√°s c√°lido: {max_temp} con {temp_mensual.max():.2f}¬∞C\")\n",
    "print(f\"Mes m√°s fr√≠o: {min_temp} con {temp_mensual.min():.2f}¬∞C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b01411",
   "metadata": {},
   "source": [
    "**Pregunta:** ¬øQu√© meses tienen mayor precipitaci√≥n?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb74993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Meses con mayor precipitaci√≥n:\n",
      "Month\n",
      "9     50.947790\n",
      "5     50.818566\n",
      "3     50.494378\n",
      "10    50.241029\n",
      "4     50.131147\n",
      "Name: Precipitation, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Tu c√≥digo aqu√≠\n",
    "# Precipitaci√≥n media por mes\n",
    "precip_mensual = climate_change.groupby('Month')['Precipitation'].mean().sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nMeses con mayor precipitaci√≥n:\")\n",
    "print(precip_mensual.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc9f249",
   "metadata": {},
   "source": [
    "**Pregunta:** ¬øExisten valores faltantes en alguna columna?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dce4e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores faltantes por columna:\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Tu c√≥digo aqu√≠\n",
    "# Verificar valores faltantes\n",
    "valores_faltantes = climate_change.isnull().sum()\n",
    "\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(valores_faltantes[valores_faltantes > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10731388",
   "metadata": {},
   "source": [
    "**Pregunta:** Agrupa por estaci√≥n del a√±o y calcula la media de temperatura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c006a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Temperatura media por estaci√≥n:\n",
      "Season\n",
      "Invierno     14.974683\n",
      "Oto√±o        14.809827\n",
      "Primavera    15.003823\n",
      "Verano       14.957014\n",
      "Name: Temperature, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Tu c√≥digo aqu√≠\n",
    "# Definir funci√≥n para determinar estaci√≥n\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Verano'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Oto√±o'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Invierno'\n",
    "    else:\n",
    "        return 'Primavera'\n",
    "\n",
    "# Aplicar funci√≥n\n",
    "climate_change['Season'] = climate_change['Month'].apply(get_season)\n",
    "\n",
    "# Calcular media por estaci√≥n\n",
    "temp_por_estacion = climate_change.groupby('Season')['Temperature'].mean()\n",
    "\n",
    "print(\"\\nTemperatura media por estaci√≥n:\")\n",
    "print(temp_por_estacion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77184d2",
   "metadata": {},
   "source": [
    "**Pregunta:** Crea una columna que clasifique los d√≠as como 'calurosos' o 'templados'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da1b54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribuci√≥n de d√≠as:\n",
      "Day_Type\n",
      "Templado    8403\n",
      "Caluroso    1597\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Tu c√≥digo aqu√≠\n",
    "# Calcular umbral (media + 1 desviaci√≥n est√°ndar)\n",
    "umbral = climate_change['Temperature'].mean() + climate_change['Temperature'].std()\n",
    "\n",
    "# Crear columna de clasificaci√≥n\n",
    "climate_change['Day_Type'] = climate_change['Temperature'].apply(\n",
    "    lambda x: 'Caluroso' if x > umbral else 'Templado'\n",
    ")\n",
    "\n",
    "print(\"\\nDistribuci√≥n de d√≠as:\")\n",
    "print(climate_change['Day_Type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dac89b0",
   "metadata": {},
   "source": [
    "**Pregunta:** Genera una pivot_table que muestre la temperatura promedio por a√±o y mes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510b6d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Temperatura promedio por a√±o y mes:\n",
      "Month         1          2          3          4          5          6   \\\n",
      "Year                                                                      \n",
      "2000   14.206357  13.932424  16.353462  14.956865  15.447593  15.312805   \n",
      "2001   14.708201  16.514600  13.973159  15.036136  14.800959  14.723588   \n",
      "2002   13.620897  14.760417  14.212325  13.850515  13.673576  13.502537   \n",
      "2003   14.885562  16.854469  14.114849  14.987196  14.129527  14.842865   \n",
      "2004   15.914895  13.717340  14.815031  15.814182  15.283723  15.279225   \n",
      "2005   15.310610  14.956032  16.763042  14.461071  16.430089  15.204628   \n",
      "2006   13.021321  14.050059  16.181762  14.232334  15.479402  16.405412   \n",
      "2007   14.419660  14.287890  14.973328  13.083154  15.425498  16.270065   \n",
      "2008   15.947948  15.317924  14.456524  14.146105  15.636002  15.028988   \n",
      "2009   15.004275  13.500589  14.986215  13.581644  13.945644  14.644463   \n",
      "2010   16.430713  16.602293  13.796567  14.304352  14.307113  14.671207   \n",
      "2011   14.799867  13.479437  15.693903  15.139654  14.684203  15.105863   \n",
      "2012   15.014508  14.846005  13.295717  15.058723  13.914326  14.940604   \n",
      "2013   14.817513  15.026508  15.169225  15.652592  15.699235  15.624625   \n",
      "2014   14.211216  17.750663  14.098651  16.129610  15.228852  13.684015   \n",
      "2015   14.241782  15.033940  14.004943  16.138518  14.196789  14.114472   \n",
      "2016   14.670316  15.497960  15.300441  15.048309  16.276688  13.696816   \n",
      "2017   14.916962  16.109878  14.875714  14.620956  14.702661  14.718316   \n",
      "2018   14.459322  13.972831  16.687060  15.402600  13.581579  15.342407   \n",
      "2019   14.979902  15.127148  15.228717  15.051345  15.698920  15.217087   \n",
      "2020   16.365128  16.494077  14.513129  13.769750  14.111491  15.371135   \n",
      "2021   15.004946  14.917552  15.611437  15.020317  14.224062  15.239940   \n",
      "2022   13.855182  16.237678  12.730452  13.669461  14.048418  14.726455   \n",
      "\n",
      "Month         7          8          9          10         11         12  \n",
      "Year                                                                     \n",
      "2000   15.628546  15.079403  14.245601  14.634586  15.791594  14.747044  \n",
      "2001   15.254576  15.039348  14.480689  14.634459  15.584229  14.721999  \n",
      "2002   15.576326  14.671967  16.328612  14.936858  15.609769  14.881162  \n",
      "2003   15.227706  15.968507  15.345826  14.831173  15.958393  14.932671  \n",
      "2004   16.452629  15.951439  14.279708  15.091279  15.018508  15.603309  \n",
      "2005   15.133922  15.070869  15.637863  15.126200  16.467725  14.171810  \n",
      "2006   14.475120  13.628186  15.726648  15.800620  14.232370  15.692140  \n",
      "2007   15.347496  15.393289  16.682545  15.696156  15.788519  15.113820  \n",
      "2008   14.423550  15.095044  14.290230  13.657560  15.499798  14.481284  \n",
      "2009   14.477702  16.043215  13.838197  13.994606  14.802935  14.848085  \n",
      "2010   14.375021  14.925134  14.717537  15.053192  14.369786  13.809852  \n",
      "2011   15.690435  15.687834  13.865234  15.437654  15.467247  16.068971  \n",
      "2012   14.006859  13.204141  15.538426  14.538936  15.288107  14.969530  \n",
      "2013   15.951572  14.614062  14.210218  14.339588  14.792342  13.711844  \n",
      "2014   15.053259  13.415877  15.484833  16.763142  15.735282  15.005282  \n",
      "2015   14.048836  14.783575  15.314595  14.618449  14.371005  14.182403  \n",
      "2016   14.551097  15.774117  13.637672  15.458059  15.202107  15.238861  \n",
      "2017   14.430206  16.142818  15.179017  13.392676  14.928116  14.321032  \n",
      "2018   14.933499  15.235965  13.976580  14.518844  13.422849  14.163839  \n",
      "2019   15.397701  14.697973  13.085429  14.792796  16.787389  15.076437  \n",
      "2020   14.828948  14.722336  16.534824  13.441375  15.383780  15.929036  \n",
      "2021   14.669112  14.603044  15.945297  15.155843  15.000113  16.138813  \n",
      "2022   15.354888  14.516170  14.715461  14.762771  16.138990  15.065756  \n"
     ]
    }
   ],
   "source": [
    "# Tu c√≥digo aqu√≠\n",
    "# Crear pivot table\n",
    "pivot_temp = pd.pivot_table(\n",
    "    climate_change,\n",
    "    values='Temperature',\n",
    "    index='Year',\n",
    "    columns='Month',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "print(\"\\nTemperatura promedio por a√±o y mes:\")\n",
    "print(pivot_temp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
